# ğŸ“ Issues para Crear en GitHub

Copia y pega estos issues en GitHub:
https://github.com/jona-mhw/ticket-2/issues/new

---

## Issue #1: ğŸ§ª Implementar pytest con fixtures y coverage >80%

### ğŸ“‹ DescripciÃ³n
Implementar suite de testing completa usando pytest para garantizar la calidad del cÃ³digo y prevenir regresiones.

### ğŸ¯ Objetivos
- [x] Setup inicial de pytest con configuraciÃ³n profesional
- [x] Fixtures compartidos para DB, usuarios, clÃ­nicas
- [x] Tests unitarios de modelos (13 modelos)
- [x] Tests de la lÃ³gica de cÃ¡lculo FPA (crÃ­tico)
- [x] Tests de autenticaciÃ³n (IAP + tradicional)
- [x] Tests de blueprints principales
- [x] Coverage report >80%
- [x] DocumentaciÃ³n de cÃ³mo correr tests

### ğŸ“ Archivos a Crear
```
tests/
â”œâ”€â”€ conftest.py              # Fixtures compartidos
â”œâ”€â”€ test_models.py           # Tests de User, Clinic, Patient, etc.
â”œâ”€â”€ test_fpa_logic.py        # Tests del cÃ¡lculo FPA (GOLD)
â”œâ”€â”€ test_auth.py             # Tests de autenticaciÃ³n
â”œâ”€â”€ test_routes_tickets.py   # Tests de CRUD tickets
â”œâ”€â”€ test_routes_admin.py     # Tests de panel admin
â”œâ”€â”€ test_routes_dashboard.py # Tests de mÃ©tricas
â””â”€â”€ pytest.ini               # ConfiguraciÃ³n pytest
```

### ğŸ¯ Casos de Prueba CrÃ­ticos
1. **FPA Calculation:**
   - CirugÃ­a ambulatoria antes de las 12pm â†’ alta mismo dÃ­a
   - CirugÃ­a ambulatoria despuÃ©s de las 12pm â†’ alta dÃ­a siguiente 8am
   - CirugÃ­a con estadÃ­a nocturna â†’ cÃ¡lculo correcto de dÃ­as
   - Casos edge: medianoche, cambio de aÃ±o, horario de verano

2. **Multi-tenancy:**
   - Usuario solo ve datos de su clÃ­nica
   - Superuser ve todas las clÃ­nicas
   - Isolation entre clÃ­nicas

3. **AutenticaciÃ³n:**
   - Login tradicional (DEV)
   - IAP authentication (QA/PROD)
   - Auto-creaciÃ³n de superusers desde IAP headers

### ğŸ› ï¸ Dependencias
```txt
pytest==7.4.3
pytest-flask==1.3.0
pytest-cov==4.1.0
pytest-mock==3.12.0
faker==20.1.0  # Para generar datos de prueba
freezegun==1.4.0  # Para mockear fechas
```

### âœ… Definition of Done
- [ ] Tests pasan en local
- [ ] Coverage >80% (verificar con `pytest --cov`)
- [ ] DocumentaciÃ³n en README sobre cÃ³mo correr tests
- [ ] Fixtures reutilizables para futuras pruebas
- [ ] Sin warnings en pytest

### ğŸ·ï¸ Labels
`testing`, `enhancement`, `priority: high`, `good first issue`

### ğŸ”— Referencias
- [DocumentaciÃ³n pytest](https://docs.pytest.org/)
- [pytest-flask](https://pytest-flask.readthedocs.io/)
- [Testing Flask Apps](https://flask.palletsprojects.com/en/latest/testing/)

---

## Issue #2: ğŸš€ Implementar CI/CD Pipeline con GitHub Actions

### ğŸ“‹ DescripciÃ³n
Automatizar testing, linting, build y deploy usando GitHub Actions para reducir errores humanos y acelerar entregas.

### ğŸ¯ Objetivos
- [x] Workflow de CI (tests + linting en cada PR)
- [x] Workflow de deploy automÃ¡tico a QA
- [x] Workflow de deploy manual a PROD
- [x] Notifications en caso de fallo
- [x] Quality gates (no merge si tests fallan)
- [x] Cache de dependencies para velocidad

### ğŸ“ Archivos a Crear
```
.github/workflows/
â”œâ”€â”€ ci.yml              # Tests + linting en cada PR
â”œâ”€â”€ deploy-qa.yml       # Auto-deploy a QA en merge a main
â”œâ”€â”€ deploy-prod.yml     # Manual deploy a PROD
â””â”€â”€ nightly-tests.yml   # Tests completos cada noche
```

### ğŸ”§ ConfiguraciÃ³n CI Workflow

```yaml
# .github/workflows/ci.yml
name: ğŸ§ª CI - Tests & Linting

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main]

jobs:
  tests:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:17
        env:
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov flake8 black

      - name: Run linting
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          black --check .

      - name: Run tests with coverage
        run: |
          pytest --cov=. --cov-report=xml --cov-report=term
        env:
          DATABASE_URL: postgresql://postgres:test_password@localhost/test_db

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: true

      - name: Comment PR with coverage
        uses: py-cov-action/python-coverage-comment-action@v3
        with:
          GITHUB_TOKEN: ${{ github.token }}

  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run security scan
        run: |
          pip install safety bandit
          safety check
          bandit -r . -f json -o bandit-report.json
```

### ğŸ¯ Quality Gates
- âœ… Todos los tests deben pasar
- âœ… Coverage mÃ­nimo: 80%
- âœ… No errores de flake8 crÃ­ticos
- âœ… Black formatting correcto
- âœ… No vulnerabilidades crÃ­ticas (safety)

### ğŸš€ Deploy Workflows
- **QA:** Auto-deploy en merge a `main`
- **PROD:** Manual trigger con aprobaciÃ³n requerida

### âœ… Definition of Done
- [ ] CI workflow funciona en PRs
- [ ] Tests se corren automÃ¡ticamente
- [ ] No se puede hacer merge si tests fallan
- [ ] Deploy a QA automÃ¡tico
- [ ] Deploy a PROD manual con botÃ³n
- [ ] Notificaciones configuradas

### ğŸ·ï¸ Labels
`ci/cd`, `automation`, `enhancement`, `priority: high`

---

## Issue #3: âš¡ Implementar Redis Cache Layer para Performance

### ğŸ“‹ DescripciÃ³n
Agregar capa de cachÃ© con Redis para mejorar performance del dashboard y reducir carga en PostgreSQL.

### ğŸ¯ Objetivos
- [x] Setup Redis en GCP Memorystore
- [x] Cache de queries frecuentes (dashboard stats)
- [x] Session store en Redis (no en cookies)
- [x] InvalidaciÃ³n inteligente de cache
- [x] MÃ©tricas de hit rate
- [x] Fallback automÃ¡tico si Redis falla

### ğŸ“Š MÃ©tricas Esperadas
- Dashboard load time: 3s â†’ <500ms (6x mÃ¡s rÃ¡pido)
- DB queries en dashboard: 15 â†’ 2
- Cache hit rate objetivo: >70%

### ğŸ› ï¸ Stack TÃ©cnico
```txt
redis==5.0.1
flask-caching==2.1.0
```

### ğŸ”§ ImplementaciÃ³n

**1. Cache de Dashboard Stats:**
```python
from flask_caching import Cache

cache = Cache(config={
    'CACHE_TYPE': 'redis',
    'CACHE_REDIS_URL': os.getenv('REDIS_URL')
})

@cache.memoize(timeout=300)  # 5 minutos
def get_dashboard_stats(clinic_id):
    # Queries pesadas aquÃ­
    return stats
```

**2. InvalidaciÃ³n Inteligente:**
```python
# Al crear/modificar ticket:
@tickets_bp.route('/create', methods=['POST'])
def create_ticket():
    # ... crear ticket ...
    cache.delete(f'dashboard_stats_{clinic_id}')
    cache.delete(f'nursing_board_{clinic_id}')
    return redirect('/')
```

**3. Session Store:**
```python
SESSION_TYPE = 'redis'
SESSION_REDIS = redis.from_url(REDIS_URL)
SESSION_PERMANENT = False
SESSION_USE_SIGNER = True
```

### ğŸ—ï¸ Infraestructura GCP
- Crear Redis instance en Memorystore
- VPC peering con Cloud Run
- Configurar in Terraform/Cloud Console

### âš ï¸ Consideraciones
- Fallback a DB si Redis falla (no romper la app)
- TTL apropiados (no cache infinito)
- Monitoreo de hit rate
- Evitar cache stampede

### âœ… Definition of Done
- [ ] Redis configurado en GCP
- [ ] Cache implementado en dashboard
- [ ] Sessions en Redis
- [ ] MÃ©tricas de hit rate visibles
- [ ] Tests de invalidaciÃ³n
- [ ] DocumentaciÃ³n de TTLs y estrategia

### ğŸ·ï¸ Labels
`performance`, `enhancement`, `priority: medium`, `infrastructure`

---

## Issue #4: ğŸ” Optimizar Queries y Resolver N+1 Problems

### ğŸ“‹ DescripciÃ³n
Identificar y resolver problemas de performance en queries de base de datos, especialmente N+1 queries que causan carga excesiva.

### ğŸ¯ Objetivos
- [x] AuditorÃ­a completa de queries
- [x] Implementar eager loading donde corresponda
- [x] Agregar indexes en columnas clave
- [x] Query profiling en endpoints lentos
- [x] Documentar slow queries

### ğŸ” N+1 Problems Identificados

**Problema 1: Nursing Board**
```python
# âŒ ANTES (N+1 query)
tickets = Ticket.query.filter_by(clinic_id=clinic_id).all()
for ticket in tickets:
    print(ticket.patient.nombre)  # Query por cada ticket!
    print(ticket.specialty.name)  # Otra query!
    print(ticket.doctor.nombre)   # Otra query!
# Total: 1 + (N * 3) queries

# âœ… DESPUÃ‰S (eager loading)
tickets = Ticket.query\
    .filter_by(clinic_id=clinic_id)\
    .options(
        joinedload(Ticket.patient),
        joinedload(Ticket.specialty),
        joinedload(Ticket.doctor)
    ).all()
# Total: 1 query con JOINs
```

**Problema 2: Dashboard Stats**
```python
# âŒ ANTES
for clinic in clinics:
    count = Ticket.query.filter_by(clinic_id=clinic.id).count()
# N queries

# âœ… DESPUÃ‰S
from sqlalchemy import func
stats = db.session.query(
    Ticket.clinic_id,
    func.count(Ticket.id)
).group_by(Ticket.clinic_id).all()
# 1 query
```

### ğŸ“Š Indexes a Crear

```sql
-- Tickets mÃ¡s buscados por clinic + status
CREATE INDEX idx_tickets_clinic_status
ON tickets(clinic_id, status);

-- BÃºsqueda por RUT de paciente
CREATE INDEX idx_patients_rut
ON patients(rut);

-- AuditorÃ­a por usuario
CREATE INDEX idx_action_audit_user_date
ON action_audit(user_id, timestamp DESC);

-- Tickets por fecha creaciÃ³n
CREATE INDEX idx_tickets_created_at
ON tickets(created_at DESC);
```

### ğŸ› ï¸ Herramientas
- Flask-DebugToolbar (ver queries en desarrollo)
- SQLAlchemy query profiling
- PostgreSQL EXPLAIN ANALYZE
- New Relic / Datadog (producciÃ³n)

### ğŸ“ˆ MÃ©tricas de Ã‰xito
- Nursing board: <100ms (actualmente ~500ms)
- Dashboard: <200ms (actualmente ~3s con 15 queries)
- Reducir queries promedio por request: 15 â†’ <5

### âœ… Definition of Done
- [ ] Audit de todos los endpoints principales
- [ ] N+1 problems resueltos
- [ ] Indexes creados y probados
- [ ] Query count reducido >50%
- [ ] DocumentaciÃ³n de patterns de queries eficientes
- [ ] Before/after benchmarks

### ğŸ·ï¸ Labels
`performance`, `database`, `tech-debt`, `priority: medium`

---

## ğŸ“ Notas para Crear Issues

1. **Ve a:** https://github.com/jona-mhw/ticket-2/issues/new
2. **Copia** cada issue completo (tÃ­tulo + descripciÃ³n)
3. **Asigna labels** manualmente (o crÃ©alos si no existen)
4. **AsÃ­gnate** a ti mismo como assignee
5. **(Opcional)** Agrega a un Project/Milestone

### ğŸ·ï¸ Labels a Crear en el Repo
- `testing` (verde)
- `ci/cd` (azul)
- `performance` (naranja)
- `database` (morado)
- `enhancement` (celeste)
- `tech-debt` (gris)
- `priority: high` (rojo)
- `priority: medium` (amarillo)
- `good first issue` (verde claro)

